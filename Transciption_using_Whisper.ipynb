{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome!"
      ],
      "metadata": {
        "id": "v8or_aCX5KKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ explanation of this notebook ]\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Want to know more?\n",
        "\n",
        "*   [Whisper's getting started guide](https://platform.openai.com/docs/guides/speech-to-text)\n",
        "*   [Whisper's API documentation](https://platform.openai.com/docs/api-reference/audio)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VWZfCCKa5Mag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First upload your audio files on the left by\n",
        "\n",
        "# Supported file types are flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm."
      ],
      "metadata": {
        "id": "iXJECVHX5LoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below, paste your API key and type the name of your audio file\n",
        "\n",
        "OPENAI_API_KEY = 'your_secret_key'          # it is important that your key is pasted within the ' ' marks.\n",
        "AUDIO_FILE = ''                             # it is important that your file path is pasted within the ' ' marks."
      ],
      "metadata": {
        "id": "UyQWlGft5PNp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIrRf_kHxNd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the necessary OpenAI software, run this cell by pressing 'shift'+'enter'\n",
        "\n",
        "!pip install openai\n",
        "import openai"
      ],
      "metadata": {
        "id": "wN0QDkwEv5Su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After the above preparation, select this cell and press 'shift'+'enter'\n",
        "\n",
        "print(\"Transcription started.\")\n",
        "with open(AUDIO_FILE, \"rb\") as audio_file:\n",
        "    transcript = openai.Audio.transcribe(api_key=OPENAI_API_KEY,\n",
        "                                model=\"whisper-1\",\n",
        "                                file=audio_file,\n",
        "                                response_format=\"text\",\n",
        "                                language=\"en\"\n",
        "                                )\n",
        "print(\"Transcription succes!\")\n",
        "\n",
        "with open(\"Transcript.txt\", 'w') as transcript_file:\n",
        "    transcript_file.write(transcript)"
      ],
      "metadata": {
        "id": "qUotOwiU6iJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f38c2c-d210-49cb-ff96-d1aa072ea469"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription started.\n",
            "Transcription succes!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ta da!\n",
        "\n",
        "On the left you can find your transcription"
      ],
      "metadata": {
        "id": "fhL6YBhw6wSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Some statistics on the transcription"
      ],
      "metadata": {
        "id": "OV-QjDTKxkxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}